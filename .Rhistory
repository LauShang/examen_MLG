# Resultado
integral_estimate <- monte_carlo(f,xinf,xsup,n)
integral_estimate
print(integral_estimate - valor_exacto)
valor_exacto = 0.524797
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
#número máximo de puntos aleatorois para el cálculo
n <- 1000000
#limites
xinf = 0
xsup=1
# Resultado
integral_estimate <- monte_carlo(f,xinf,xsup,n)
print(integral_estimate)
print(integral_estimate - valor_exacto)
valor_exacto = 0.524797
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
#número máximo de puntos aleatorois para el cálculo
n <- c(1000,10000,100000,1000000)
valor_exacto = 0.524797
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
#número máximo de puntos aleatorois para el cálculo
n <- c(1000,10000,100000,1000000)
#limites
xinf = 0
xsup=1
# resultados
monte_carlo(f,xinf,xsup,n)
monte_carlo(f,xinf,xsup,1000)
monte_carlo(f,xinf,xsup,10000)
help(sapply)
sapply(n,monte_carlo(f,xinf,xsup,n))
sapply(n,monte_carlo
)
valor_exacto = 0.524797
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
#número máximo de puntos aleatorois para el cálculo
n <- c(1000,10000,100000,1000000)
#limites
xinf = 0
xsup=1
# resultados
integral_estimate <- monte_carlo(f,xinf,xsup,n)
print(integral_estimate)
print(integral_estimate - valor_exacto)
valor_exacto = 0.524797
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
#número máximo de puntos aleatorois para el cálculo
n <- 100000
#limites
xinf = 0
xsup=1
# resultados
integral_estimate <- monte_carlo(f,xinf,xsup,n)
print(integral_estimate)
print(integral_estimate - valor_exacto)
runif(N, min = 0, max = 1)
runif(1000, min = 0, max = 1)
runif(20, min = 0, max = 1)
plot(runif(20, min = 0, max = 1))
plot(runif(2000, min = 0, max = 1))
plot(runif(20000, min = 0, max = 1))
plot(runif(200, min = 0, max = 1))
g <- function(x) {
return(x^2)  # Por ejemplo, una función cuadrática acotada en [0, 1]
}
N <- 10000
# Generar muestras utilizando la densidad de importancia f(x)
samples <- runif(N, min = 0, max = 1)
g(samples)
N[1:2]
N
samples[1:3]
samples
head(samples)
head(g(samples))
samples[2]
samples[2]^2
help(is.finite())
help(is.finite
)
is.finite(1)
is.finite(inf)
is.finite(2/3)
is.finite(2/0)
f
integrate(f, 0, 1)$value
library(tidyverse)
library(patchwork)
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
valor_exacto = integrate(f, 0, 1)$value
#número máximo de puntos aleatorois para el cálculo
n <- 100000
#limites
xinf = 0
xsup=1
# resultados
integral_estimate <- monte_carlo(f,xinf,xsup,n)
print(integral_estimate)
print(integral_estimate - valor_exacto)
abs(1)
abs(-1)
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
valor_exacto = integrate(f, 0, 1)$value
#limites
xinf <- 0
xsup <- 1
# resultados
trigger <- TRUE
n <- 10
while (diff > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff <- abs(integral_estimate - valor_exacto)
n <- n + 5
}
diff
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
valor_exacto = integrate(f, 0, 1)$value
#limites
xinf <- 0
xsup <- 1
# resultados
trigger <- TRUE
n <- 10
diff_int <- 10
while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff <- abs(integral_estimate - valor_exacto)
n <- n + 5
}
while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff_int <- abs(integral_estimate - valor_exacto)
n
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
valor_exacto = integrate(f, 0, 1)$value
#limites
xinf <- 0
xsup <- 1
# resultados
trigger <- TRUE
n <- 10
diff_int <- 10
while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff_int <- abs(integral_estimate - valor_exacto)
n <- n + 5
}
#while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff_int <- abs(integral_estimate - valor_exacto)
diff_int
diff_int > 0.001
n
n <- 10
n
n <- n + 5
n
#while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff_int <- abs(integral_estimate - valor_exacto)
diff_int
diff_int > 0.001
# Definimos la función a integrar
f <- function(x) {
exp(-x) / (1 + x^2)
}
valor_exacto = integrate(f, 0, 1)$value
#limites
xinf <- 0
xsup <- 1
# resultados
trigger <- TRUE
n <- 10
diff_int <- 10
while (diff_int > 0.001) {
integral_estimate <- monte_carlo(f,xinf,xsup,n)
diff_int <- abs(integral_estimate - valor_exacto)
if (diff_int > 0.001) {
n <- n + 5
}
}
n
sprintf("Tamaño de muestra aproximado para obtener un error de estimación máximo de ±0.001: %d",n)
tinytex::install_tinytex()
library(tidyverse)
library(patchwork)
# Cargamos las librerías necesarias
library(stats)
# Definimos la función a integrar
integrand <- function(x) {
exp(-x) / (1 + xˆ2)
}
2
# Realizamos una estimación inicial con un tamaño de muestra moderado para determinar la varianza
initial_n <- 10000
initial_sample <- integrand(runif(initial_n, 0, 1))
# Cargamos las librerías necesarias
library(stats)
# Definimos la función a integrar
integrand <- function(x) {
exp(-x) / (1 + x^2)
}
2
# Realizamos una estimación inicial con un tamaño de muestra moderado para determinar la varianza
initial_n <- 10000
initial_sample <- integrand(runif(initial_n, 0, 1))
initial_estimate <- mean(initial_sample)
initial_variance <- var(initial_sample)
# Calculamos el tamaño de muestra necesario para obtener un error máximo de ±0.001 con 95% de confianza
# Usamos la fórmula n = (Z * sigma / E)ˆ2, donde Z es el valor de Z para el 95% de confianza, sigma es z_value <- qnorm(0.975) # Valor Z para 95% de confianza
error_margin <- 0.001 # Error máximo permitido
required_n <- ceiling((z_value * sqrt(initial_variance) / error_margin)ˆ2)
# Cargamos las librerías necesarias
library(stats)
# Definimos la función a integrar
integrand <- function(x) {
exp(-x) / (1 + x^2)
}
2
# Realizamos una estimación inicial con un tamaño de muestra moderado para determinar la varianza
initial_n <- 10000
initial_sample <- integrand(runif(initial_n, 0, 1))
initial_estimate <- mean(initial_sample)
initial_variance <- var(initial_sample)
# Calculamos el tamaño de muestra necesario para obtener un error máximo de ±0.001 con 95% de confianza
# Usamos la fórmula n = (Z * sigma / E)ˆ2, donde Z es el valor de Z para el 95% de confianza, sigma es z_value <- qnorm(0.975) # Valor Z para 95% de confianza
error_margin <- 0.001 # Error máximo permitido
required_n <- ceiling((z_value * sqrt(initial_variance) / error_margin)^2)
# Cargamos las librerías necesarias
library(stats)
# Definimos la función a integrar
integrand <- function(x) {
exp(-x) / (1 + x^2)
}
2
# Realizamos una estimación inicial con un tamaño de muestra moderado para determinar la varianza
initial_n <- 10000
initial_sample <- integrand(runif(initial_n, 0, 1))
initial_estimate <- mean(initial_sample)
initial_variance <- var(initial_sample)
# Calculamos el tamaño de muestra necesario para obtener un error máximo de ±0.001 con 95% de confianza
# Usamos la fórmula n = (Z * sigma / E)ˆ2, donde Z es el valor de Z para el 95% de confianza, sigma es
z_value <- qnorm(0.975) # Valor Z para 95% de confianza
error_margin <- 0.001 # Error máximo permitido
required_n <- ceiling((z_value * sqrt(initial_variance) / error_margin)^2)
# Imprimimos el tamaño de muestra necesario y la estimación inicial
print(paste("Tamaño de muestra necesario:", required_n))
library(tidyverse)
library(patchwork)
exact_value = 0.5
monte_carlo <- function(f, xinf, xsup, n) {
# Generamos n puntos aleatorios
x <- runif(n, xinf, xsup)
# Evaluamos f en un conjunto denso para encontrar un máximo más representativo
f_max <- max(f(x))
# Generamos n puntos aleatorios en el rango [0, f_max]
y <- runif(n, 0, f_max)
# Calculamos los puntos que caen debajo de la curva de f
points_in_curve <- sum(y <= f(x))
# Calculamos el área bajo la curva
integral_estimate <- (points_in_curve / n) * (xsup - xinf) * f_max
return(integral_estimate)
}
f_sin <- function(x) sin(x)
n <- 1000000
xinf <- 0
xsup <- pi/3
# Ejecución de la función mejorada
integral_estimate <- monte_carlo(f_sin, xinf, xsup, n)
sprintf("Integración por Monte Carlo %.4f mientras que el valor exacto es %.4f",integral_estimate,exact_value)
# Define un vector de valores x para evaluar la FDA
monte_carlo_estimator <- function(x, n = 10000) {
# Generar n números aleatorios beta(3, 3)
valores_r_beta <- rbeta(n, 3, 3)
monte_carlo_estimate <- mean(valores_r_beta <= x)
return(monte_carlo_estimate)
}
# Calcular los estimados de Monte Carlo de F(x) para x = 0.1, 0.2, ..., 0.9
x_values <- seq(0.1, 0.9, by = 0.1)
monte_carlo_estimates <- sapply(x_values, monte_carlo_estimator)
# Calcular los valores de referencia de F(x) utilizando la función pbeta de R
reference_values <- pbeta(x_values, 3, 3)
# Mostrar los resultados
results <- tibble(x = x_values, Estimador_MC = monte_carlo_estimates, PBETA = reference_values)
print(results)
# Cargamos las librerías necesarias
library(stats)
# Definimos la función a integrar
integrand <- function(x) {
exp(-x) / (1 + x^2)
}
2
# Realizamos una estimación inicial con un tamaño de muestra moderado para determinar la varianza
initial_n <- 10000
initial_sample <- integrand(runif(initial_n, 0, 1))
initial_estimate <- mean(initial_sample)
initial_variance <- var(initial_sample)
# Calculamos el tamaño de muestra necesario para obtener un error máximo de ±0.001 con 95% de confianza
# Usamos la fórmula n = (Z * sigma / E)ˆ2, donde Z es el valor de Z para el 95% de confianza, sigma es
z_value <- qnorm(0.975) # Valor Z para 95% de confianza
error_margin <- 0.001 # Error máximo permitido
required_n <- ceiling((z_value * sqrt(initial_variance) / error_margin)^2)
# Imprimimos el tamaño de muestra necesario y la estimación inicial
print(paste("Tamaño de muestra necesario:", required_n))
monte_carlo(integrand,0,1,345)
integrate(integrand,0,1)
integrate(integrand,0,1)$value
integrate(integrand,0,1)$value - monte_carlo(integrand,0,1,345)
integrate(integrand,0,1)$value - monte_carlo(integrand,0,1,1000)
integrate(integrand,0,1)$value - monte_carlo(integrand,0,1,230631)
integrand(runif(initial_n, 0, 1))
install.packages("rstanarm")
y <- rnorm(N, 5, 2)
library(rstanarm)
# Sample data
set.seed(123)
N <- 100
y <- rnorm(N, 5, 2)
x <- rnorm(N)
# Data list
data <- list(N = N, y = y, x = x)
# Fit the model
fit <- stan_fit(model_code = "my_model.stan", data = data)
help(stan_fit)
library(rstanarm)
data
data[0]
# Fit the model
fit <- stan_fit(model_code = "my_model.stan", data = data)
# Print summary
summary(fit)
install.packages("rstanarm")
install.packages("rstanarm")
install.packages("stan")
data
installed.packages()
try(library(rstanarm))
help("stan_lm.fit")
# Fit the model
fit <- stan_lm.fit(model_code = "my_model.stan", data = data)
# Fit the model
fit <- stan_glm.fit(model_code = "my_model.stan", data = data)
install_cmdstan()
library(cmdstanr)
installed.packages(cmdstan)
installed.packages(cmdstanr)
install.packages("rstan")
install.packages("rstan")
library(rstan)
# Ajustar el modelo
fit <- stan(
file = 'my_model.stan', # O reemplace por un string que contenga el modelo
data = stan_data,
iter = 2000,
chains = 4
)
set.seed(42) # Para reproducibilidad
# Generar datos para x
x_data <- seq(0, 10, length.out = 100)
# Generar datos para y usando una relación lineal simple y = 2*x + 1 con ruido gaussiano
y_data <- 2 * x_data + 1 + rnorm(100, mean = 0, sd = 2)
N <- length(x_data)
stan_data <- list(N = N, x = x_data, y = y_data)
# Ajustar el modelo
fit <- stan(
file = 'my_model.stan', # O reemplace por un string que contenga el modelo
data = stan_data,
iter = 2000,
chains = 4
)
model_code <- "
data {
int<lower=0> N; // Número de observaciones
vector[N] x; // Variable predictora
vector[N] y; // Variable de respuesta
}
parameters {
real alpha; // Intercepto
real beta; // Pendiente
real<lower=0> sigma; // Desviación estándar del error
}
model {
y ~ normal(alpha + beta * x, sigma); // Modelo lineal
}
"
# Ajustar el modelo
fit <- stan(
model_code = model_code, # O reemplace por un string que contenga el modelo
data = stan_data,
iter = 2000,
chains = 4
)
summary(fit)
rnorm(100, mean = 0, sd = 2)
mean(rnorm(100, mean = 0, sd = 2))
mean(rnorm(100, mean = 0, sd = 2))
mean(rnorm(1000, mean = 0, sd = 2))
mean(rnorm(1000, mean = 0, sd = 2))
plot(rnorm(100, mean = 0, sd = 2))
hist(rnorm(100, mean = 0, sd = 2))
hist(rnorm(10000, mean = 0, sd = 2))
# Definir la función de coste
cost_function <- function(vars, b1, b2) {
alpha <- vars[1]
beta <- vars[2]
# Definir las ecuaciones como antes
eq1 <- alpha / (alpha + beta) - b1
eq2 <- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1)) - b2
# La función de coste es la suma de los cuadrados de las ecuaciones
cost <- sum(eq1^2, eq2^2)
return(cost)
}
# Valores de b1 y b2 como en el ejemplo
b1 <- 0.6
b2 <- 0.04^2
# Estimación inicial
init_guess <- c(1, 1)
# Usar optim para minimizar la función de coste
result <- optim(par = init_guess, fn = cost_function, b1 = b1, b2 = b2)
# Imprimir los resultados
print(result$par)
results
result
rbeta(10,result$par[0],result$par[0])
rbeta(10,result$par[0],result$par[1])
result$par[0]
result$par
result$par[1]
result$par[2]
rbeta(10,result$par[1],result$par[2])
mean(rbeta(10000,result$par[1],result$par[2]))
sd(rbeta(10000,result$par[1],result$par[2]))
help dbeta(x, shape1 = alpha, shape2 = beta)
help(dbeta(x, shape1 = alpha, shape2 = beta))
help(dbeta)
x
x <- seq(0, 1, length.out = 21)
x
dbeta(x, shape1 = alpha, shape2 = beta)
alpha <- result$par[1]
beta <- result$par[2]
dbeta(x, shape1 = alpha, shape2 = beta)
plot(dbeta(x, shape1 = alpha, shape2 = beta))
line(dbeta(x, shape1 = alpha, shape2 = beta))
x <- seq(0, 1, length.out = 100)
x
plot(dbeta(x, shape1 = alpha, shape2 = beta))
help(plot)
plot(dbeta(x, shape1 = alpha, shape2 = beta),type ='l')
plot(dbeta(x, shape1 = 2, shape2 = 2),type ='l')
plot(dbeta(x, shape1 = 0.5, shape2 = 0.5),type ='l')
x <- seq(0, 2, length.out = 20)
plot(dbeta(x, shape1 = 0.5, shape2 = 0.5),type ='l')
x <- seq(0, 1, length.out = 20)
plot(dbeta(x, shape1 = 0.5, shape2 = 0.5),type ='l')
x <- seq(0, 1, length.out = 10)
plot(dbeta(x, shape1 = 0.5, shape2 = 0.5),type ='l')
library(rstan)
install_cmdstan()
stan_version()
if (!requireNamespace("remotes", quietly = TRUE))
install.packages("remotes")
remotes::install_github("stan-dev/cmdstanr")
cmdstanr::install_cmdstan()
!cmdstanr::check_cmdstan_toolchain()
cmdstanr::check_cmdstan_toolchain()
library(cmdstanr)
getwd()
setwd('Documents/ITAM/métodos_lineales_generalizados/')
getwd()
setwd('parcial_1/')
stan_file <- "my_model.stan"
# Compila el modelo
mod <- cmdstan_model(stan_file)
# Generar datos sintéticos
set.seed(123) # Para reproducibilidad
N <- 100
x <- rnorm(N, 10, 2)
y <- 2 + 1.5 * x + rnorm(N, 0, 1)
data_list <- list(N = N, x = x, y = y)
# Ajustar el modelo a los datos
fit <- mod$sample(data = data_list, num_chains = 4, parallel_chains = 4)
# Ver los resultados
fit$summary()
